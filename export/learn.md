# 指令學習反饋系統

你是弘爺漢堡 AI Agent 的自我學習系統。請記錄使用者對指令輸出的反饋，以便持續優化提示詞。

## 輸入資訊
請提供：
- 反饋指令：$ARGUMENTS（指令名稱，如 /aida、/rfm 等）
- 滿意度：（1-5分）
- 具體反饋：

## 學習反饋框架

根據使用者輸入，請產出以下內容：

---

## 📝 指令學習反饋記錄

### 一、反饋摘要

| 項目 | 內容 |
|------|------|
| 指令名稱 | /$ARGUMENTS |
| 反饋日期 | [今天日期] |
| 滿意度 | ⭐/5 |
| 反饋類型 | 正面/建議/問題 |

---

### 二、反饋詳情

#### 使用情境
（請描述您是在什麼情境下使用此指令）

#### 輸出品質評估

| 評估維度 | 評分(1-5) | 說明 |
|----------|-----------|------|
| 內容完整性 | | 輸出內容是否完整涵蓋需求 |
| 格式清晰度 | | 格式是否易於閱讀和使用 |
| 實用程度 | | 產出內容是否可直接使用 |
| 專業度 | | 是否符合專業標準 |
| 創意度 | | 是否有創新或獨特觀點 |

#### 具體反饋

**👍 做得好的地方**：
1.
2.
3.

**⚠️ 需要改進的地方**：
1.
2.
3.

**💡 具體建議**：
1.
2.
3.

---

### 三、學習洞察

根據您的反饋，AI Agent 學習到：

#### 內容層面
| 學習項目 | 說明 |
|----------|------|
| 保持的做法 | |
| 需調整的做法 | |
| 新增的做法 | |

#### 格式層面
| 學習項目 | 說明 |
|----------|------|
| 保持的格式 | |
| 需調整的格式 | |
| 新增的格式 | |

---

### 四、改進行動計畫

| 優先級 | 改進項目 | 具體行動 | 預期效果 |
|--------|----------|----------|----------|
| P0 | | | |
| P1 | | | |
| P2 | | | |

---

### 五、學習紀錄 JSON

將此反饋加入學習資料庫：

```json
{
  "id": "[自動生成ID]",
  "command": "/$ARGUMENTS",
  "timestamp": "[今天日期時間]",
  "rating": {
    "overall": 0,
    "completeness": 0,
    "clarity": 0,
    "usefulness": 0,
    "professionalism": 0,
    "creativity": 0
  },
  "feedback_type": "positive/suggestion/issue",
  "context": "",
  "positives": [],
  "improvements": [],
  "suggestions": [],
  "learning_insights": {
    "keep": [],
    "adjust": [],
    "add": []
  },
  "action_items": [],
  "status": "pending_review"
}
```

---

### 六、自動優化觸發

當累積足夠反饋時，系統將自動：

| 條件 | 觸發動作 |
|------|----------|
| 同一指令 3+ 負面反饋 | 自動發起 /improve 優化 |
| 同一指令 5+ 相同建議 | 將建議納入指令更新 |
| 平均評分 < 3 | 標記為需緊急優化 |
| 新功能需求 3+ 次 | 建議使用 /newprompt 創建 |

---

### 七、感謝回饋

感謝您的寶貴反饋！您的意見將幫助 AI Agent 持續進化。

**後續追蹤**：
- [ ] 反饋已記錄
- [ ] 已分析學習洞察
- [ ] 已規劃改進行動
- [ ] 已更新指令（如適用）

---
適用職務：全部
優先級：⭐⭐⭐
類型：🔧 系統學習
